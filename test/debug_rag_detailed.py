import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from services.rag_custom_service import rag_service
from services.embedding_service import embedding_service
import numpy as np

print("\n" + "="*70)
print("ğŸ” RAG ê²€ìƒ‰ ì‹¬ì¸µ ë””ë²„ê¹…")
print("="*70)

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
test_query = "EU ETS"

# 1. ì¿¼ë¦¬ ì„ë² ë”©
print(f"\n1ï¸âƒ£ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±:")
print(f"   ì§ˆë¬¸: {test_query}")
query_embedding = embedding_service.embed_text(test_query)
print(f"   âœ… ì°¨ì›: {len(query_embedding)}")
print(f"   ìƒ˜í”Œ: {query_embedding[:3]}")

# 2. ì €ì¥ëœ ì²­í¬ ì¡°íšŒ
print(f"\n2ï¸âƒ£ ì €ì¥ëœ ëª¨ë“  ì²­í¬ ì¡°íšŒ:")
response = rag_service.supabase_service.client.table("document_chunks").select("*").execute()
all_chunks = response.data
print(f"   âœ… ì´ ì²­í¬ ìˆ˜: {len(all_chunks)}")

# 3. ê° ì²­í¬ë³„ ìœ ì‚¬ë„ ê³„ì‚°
print(f"\n3ï¸âƒ£ ì²­í¬ë³„ ìœ ì‚¬ë„ ê³„ì‚°:")
similarities = []

for i, chunk in enumerate(all_chunks):
    content = chunk.get('content', '')[:50]
    chunk_embedding = chunk.get('embedding', [])

    # ìœ ì‚¬ë„ ê³„ì‚°
    similarity = rag_service._cosine_similarity(query_embedding, chunk_embedding)
    similarities.append({
        'chunk_id': chunk.get('id'),
        'content': content,
        'similarity': similarity,
        'embedding_type': type(chunk_embedding).__name__,
        'embedding_sample': str(chunk_embedding)[:50] if isinstance(chunk_embedding, str) else 'array'
    })

    print(f"   {i+1}. ìœ ì‚¬ë„: {similarity:.4f} | {content}...")

# 4. ìƒìœ„ 5ê°œ ì²­í¬ í™•ì¸
print(f"\n4ï¸âƒ£ ìƒìœ„ 5ê°œ ì²­í¬ (ìœ ì‚¬ë„ ê¸°ì¤€):")
top_5 = sorted(similarities, key=lambda x: x['similarity'], reverse=True)[:5]
for i, item in enumerate(top_5, 1):
    print(f"   {i}. ìœ ì‚¬ë„: {item['similarity']:.4f} | {item['content']}...")
    print(f"      ì„ë² ë”© íƒ€ì…: {item['embedding_type']}")

# 5. search_relevant_chunks ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œ
print(f"\n5ï¸âƒ£ search_relevant_chunks ë©”ì„œë“œ í…ŒìŠ¤íŠ¸:")
try:
    relevant_chunks = rag_service.search_relevant_chunks(test_query, top_k=5)
    print(f"   âœ… ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(relevant_chunks)}")
    for i, chunk in enumerate(relevant_chunks, 1):
        content = chunk.get('content', '')[:50]
        similarity = chunk.get('similarity', 0)
        print(f"   {i}. ìœ ì‚¬ë„: {similarity:.4f} | {content}...")
except Exception as e:
    print(f"   âŒ ì˜¤ë¥˜: {e}")
    import traceback
    traceback.print_exc()

# 6. ìµœê³  ìœ ì‚¬ë„ ë¶„ì„
print(f"\n6ï¸âƒ£ ìœ ì‚¬ë„ í†µê³„:")
all_sims = [s['similarity'] for s in similarities]
if all_sims:
    print(f"   ìµœê³  ìœ ì‚¬ë„: {max(all_sims):.4f}")
    print(f"   ìµœì € ìœ ì‚¬ë„: {min(all_sims):.4f}")
    print(f"   í‰ê·  ìœ ì‚¬ë„: {np.mean(all_sims):.4f}")
    print(f"   ì¤‘ì•™ê°’ ìœ ì‚¬ë„: {np.median(all_sims):.4f}")

print("\n" + "="*70)
