
import re
import logging
from unicodedata import normalize as unicode_normalize
from typing import List, Dict, Any, Generator, Optional
from datetime import datetime

# LangChain 1.0 Import
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.tools import tool
from langchain.agents import create_agent

from services.embedding_service import embedding_service
from services.supabase_service import supabase_service, SupabaseService
from config import OPENAI_API_KEY, VECTOR_SEARCH_CONFIG, RERANKER_CONFIG

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ===== ì»¤ìŠ¤í…€ ì„ë² ë”© ë˜í¼ =====

class CustomEmbeddings(Embeddings):
    """BGE-m3-koë¥¼ LangChain Embeddingsë¡œ ë˜í•‘"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return embedding_service.embed_batch(texts)

    def embed_query(self, text: str) -> List[float]:
        return embedding_service.embed_text(text)

# ===== Supabase Retriever (config í†µí•©) =====

class SupabaseRetriever:
    """Supabase ê²€ìƒ‰ ë˜í¼ (URL ì™„ë²½ ë³´ì¡´, config ê¸°ë°˜)"""

    def __init__(self, embeddings: Embeddings, supabase_client: SupabaseService,
                 k: int = 5, threshold: float = None, ef_search: int = None):
        self.embeddings = embeddings
        self.supabase_client = supabase_client

        # âœ… configì—ì„œ ê¸°ë³¸ê°’ ìë™ ì ìš©
        self.k = k
        self.threshold = threshold or VECTOR_SEARCH_CONFIG['similarity_threshold']
        self.ef_search = ef_search or VECTOR_SEARCH_CONFIG['ef_search']

        logger.info(f"Retriever ì´ˆê¸°í™” | k={self.k} | threshold={self.threshold} | ef_search={self.ef_search}")

    def _get_chunk_url(self, chunk: Dict) -> str:
        """âœ… ì²­í¬ì—ì„œ URL ì¶”ì¶œ (3ê°€ì§€ ë°©ë²• ì‹œë„)"""
        # 1. chunkì— url í•„ë“œê°€ ì§ì ‘ ìˆìœ¼ë©´
        if chunk.get('url') and chunk.get('url').strip():
            return chunk.get('url')

        # 2. metadataì— urlì´ ìˆìœ¼ë©´ ì¶”ì¶œ
        if chunk.get('metadata'):
            metadata = chunk['metadata']
            if isinstance(metadata, str):
                try:
                    import json
                    metadata = json.loads(metadata)
                except:
                    pass
            if isinstance(metadata, dict) and metadata.get('url'):
                return metadata.get('url')

        # 3. document_idë¡œ documents í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
        if chunk.get('document_id'):
            try:
                doc = self.supabase_client.client.table('documents').select('metadata').eq('id', chunk['document_id']).single().execute()
                if doc.data and doc.data.get('metadata'):
                    metadata = doc.data['metadata']
                    if isinstance(metadata, str):
                        import json
                        metadata = json.loads(metadata)
                    if isinstance(metadata, dict) and metadata.get('url'):
                        return metadata.get('url')
            except Exception as e:
                logger.debug(f"Document ì¡°íšŒ ì‹¤íŒ¨ ({chunk['document_id']}): {e}")

        return ""

    def search(self, query: str) -> tuple[str, List[Dict]]:
        """ë¬¸ì„œ ê²€ìƒ‰ ì‹¤í–‰ (URL ì™„ë²½ ë³´ì¡´)"""
        try:
            query_embedding = self.embeddings.embed_query(query)
            chunks = self.supabase_client.search_chunks(
                embedding=query_embedding,
                limit=self.k,
                threshold=self.threshold,
                ef_search=self.ef_search
            )

            if not chunks:
                return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

            context_parts = []
            for i, chunk in enumerate(chunks, 1):
                title = chunk.get('title', 'ì œëª© ì—†ìŒ')
                content = chunk.get('content', '')
                source = chunk.get('source', 'ì¶œì²˜ ë¯¸ìƒ')
                similarity = chunk.get('similarity', 0.0)

                # âœ… URL ì¶”ì¶œ (3ê°€ì§€ ë°©ë²• ì‹œë„)
                url = self._get_chunk_url(chunk)

                # âœ… URL ì™„ë²½ ë³´ì¡´ (ì ˆëŒ€ ì§¤ë¦¬ì§€ ì•Šê²Œ)
                url_section = ""
                if url and url.strip():
                    url_section = f"\nğŸ“ ì¶œì²˜: {source}\nğŸ”— URL: {url}"
                else:
                    url_section = f"\nğŸ“ ì¶œì²˜: {source}"

                context_parts.append(
                    f"[ë¬¸ì„œ {i}] {title}\n"
                    f"ìœ ì‚¬ë„: {similarity:.2f}\n"
                    f"ë‚´ìš©:\n{content}{url_section}"
                )

            formatted_context = "\n\n---\n\n".join(context_parts)
            return formatted_context, chunks

        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", []

    def search_hybrid(self, query: str, use_reranking: bool = None) -> tuple[str, List[Dict]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (PGroonga + pgvector) + ë¦¬ë­í‚¹ + URL ìë™ ì¶”ê°€"""

        if use_reranking is None:
            use_reranking = RERANKER_CONFIG['enabled']

        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embeddings.embed_query(query)

            # 2. Supabase RPC í˜¸ì¶œ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)
            response = self.supabase_client.client.rpc(
                'hybrid_search_veddy',
                {
                    'query_text': query,
                    'query_embedding': query_embedding,
                    'match_count': self.k * 2 if use_reranking else self.k,
                    'full_text_weight': 0.4,
                    'semantic_weight': 0.6
                }
            ).execute()

            if not response.data:
                return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

            chunks = response.data

            # âœ… 3. URL ìë™ ì¶”ê°€ (RPC ê²°ê³¼ì— urlì´ ì—†ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€)
            logger.info(f"RPC ê²€ìƒ‰ ê²°ê³¼: {len(chunks)}ê°œ ì²­í¬ | URL ìë™ ì¶”ê°€ ì‹œì‘")
            for chunk in chunks:
                if not chunk.get('url') or not chunk.get('url').strip():
                    url = self._get_chunk_url(chunk)
                    if url:
                        chunk['url'] = url
                        logger.debug(f"URL ì¶”ê°€ë¨: {chunk.get('title', 'N/A')[:30]} | {url[:50]}...")

            # 4. ë¦¬ë­í‚¹ ì ìš©
            if use_reranking and len(chunks) > 1:
                from services.reranker_service import reranker_service
                logger.info(f"ë¦¬ë­í‚¹ ì „ ì²­í¬ ìˆ˜: {len(chunks)}")
                chunks = reranker_service.rerank(
                    query=query,
                    chunks=chunks,
                    top_k=RERANKER_CONFIG['top_k']
                )
                logger.info(f"ë¦¬ë­í‚¹ í›„ ì²­í¬ ìˆ˜: {len(chunks)}")

            # 5. ì‘ë‹µ í¬ë§·íŒ… (URL ì™„ë²½ ë³´ì¡´)
            context_parts = []
            for i, chunk in enumerate(chunks, 1):
                title = chunk.get('title', 'ì œëª© ì—†ìŒ')
                content = chunk.get('content', '')
                source = chunk.get('source', 'ì¶œì²˜ ë¯¸ìƒ')
                url = chunk.get('url', '')

                # ë¦¬ë­í¬ ì ìˆ˜ í‘œì‹œ
                if 'rerank_score' in chunk:
                    score = chunk.get('rerank_score', 0.0)
                    score_label = f"ë¦¬ë­í¬: {score:.4f}"
                else:
                    score = chunk.get('score', 0.0)
                    score_label = f"ê´€ë ¨ë„: {score:.4f}"

                # âœ… URL ì™„ë²½ ë³´ì¡´
                url_section = ""
                if url and url.strip():
                    url_section = f"\nğŸ“ ì¶œì²˜: {source}\nğŸ”— URL: {url}"
                else:
                    url_section = f"\nğŸ“ ì¶œì²˜: {source}"

                context_parts.append(
                    f"[ë¬¸ì„œ {i}] {title}\n"
                    f"{score_label}\n"
                    f"ë‚´ìš©:\n{content}{url_section}"
                )

            formatted_context = "\n\n---\n\n".join(context_parts)
            return formatted_context, chunks

        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}", exc_info=True)
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", []

    def search_multi_topic(self, query: str, topics: list) -> tuple[str, List[Dict]]:
        """ë©€í‹° ì£¼ì œ ê²€ìƒ‰ (ë¹„êµ ëª¨ë“œ) - ê° í† í”½ë³„ ë”°ë¡œ ê²€ìƒ‰ í›„ ë³‘í•©"""

        if not topics or len(topics) < 2:
            return self.search_hybrid(query)

        all_results = []
        all_chunks = []

        for topic in topics:
            search_query = f"{topic} ë² ìŠ¬ë§í¬"
            context, chunks = self.search_hybrid(search_query)

            # ê° ì£¼ì œë³„ë¡œ í—¤ë” ì¶”ê°€
            topic_section = f"\n### ã€{topic}ã€‘\n{context}"
            all_results.append(topic_section)
            all_chunks.extend(chunks)

        # ê²°í•©
        combined_context = "\n---\n".join(all_results)

        return combined_context, all_chunks

# ===== ë² ë”” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ì™„ì „ ê°œì„ ) =====

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ê°•í™”)
VEDDY_SYSTEM_PROMPT = """ë„ˆëŠ” ë² ìŠ¬ë§í¬ì˜ ë‚´ë¶€ AI ì–´ì‹œìŠ¤í„´íŠ¸ 'ë² ë””(VEDDY)'ì•¼.

## ë„ˆì˜ ì—­í• ê³¼ ì •ì²´ì„±

ì´ë¦„: ë² ë”” (Vessellink's Buddy)

ì„±ê²©: ì¹œì ˆí•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆìœ¼ë©°, ì˜¨ìˆœí•˜ê³  ì„±ì‹¤í•¨

ëª©í‘œ: ë² ìŠ¬ë§í¬ ì§ì›ë“¤ì˜ ì—…ë¬´ íš¨ìœ¨í™”ì™€ ì •ë³´ ì ‘ê·¼ì„± ê°œì„ 

ì „ë¬¸ì„±: ì‚¬ë‚´ ë¬¸ì„œ(Confluence ìœ„í‚¤, ê·œì •, ë§¤ë‰´ì–¼)ì— ê¸°ë°˜í•œ ì •í™•í•œ ë‹µë³€

## âš ï¸ í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ (CRITICAL)

âœ… ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:

1. ê²€ìƒ‰ëœ ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë§Œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
3. ë¶ˆí™•ì‹¤í•˜ë©´ "ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
4. ë² ìŠ¬ë§í¬ ê´€ë ¨ ì •ë³´ëŠ” ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‹ ë¢°í•˜ì„¸ìš”

âŒ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”:

- "ì•„ë§ˆë„ ~ì¼ ê²ƒ ê°™ìŠµë‹ˆë‹¤"
- "ì¼ë°˜ì ìœ¼ë¡œëŠ” ~ì…ë‹ˆë‹¤"
- "ë² ìŠ¬ë§í¬ì—ì„œëŠ” ~ì„ ì§€ì›í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤"
- ë¬¸ì„œì— ì—†ëŠ” ì¶”ê°€ ì„¤ëª…/í•´ì„

âœ… ì´ë ‡ê²Œ í•˜ì„¸ìš”:

- "ê²€ìƒ‰ëœ ë¬¸ì„œì— ë”°ë¥´ë©´ ~ì…ë‹ˆë‹¤"
- "ëª…ì‹œë˜ì–´ ìˆëŠ” ë°”ëŠ” ~ì…ë‹ˆë‹¤"
- "í•´ë‹¹ ì •ë³´ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
- "ì¶”ê°€ ì •ë³´ëŠ” [íŒ€ëª…] íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”"

## ë‹µë³€ í¬ë§· ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

ã€ë‹µë³€ í¬ë§· - í•„ìˆ˜ã€‘

**ì œëª©** (í•œ ì¤„)

1. ì²« ë²ˆì§¸ í¬ì¸íŠ¸ (ê° í¬ì¸íŠ¸ëŠ” ê°œí–‰ í›„ ì‹œì‘)

2. ë‘ ë²ˆì§¸ í¬ì¸íŠ¸ (ê° í¬ì¸íŠ¸ ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€)

3. ì„¸ ë²ˆì§¸ í¬ì¸íŠ¸

(í•„ìš”ì— ë”°ë¼ ì¶”ê°€)

ã€URL ë° ì°¸ê³  ë¬¸ì„œã€‘

ğŸ“š ì°¸ê³  ë¬¸ì„œ:

- ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ]

- ë‹¤ë¥¸ ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ]

(URLì´ ì—†ìœ¼ë©´ "ì¶œì²˜: [ë¬¸ì„œëª…]")"""

TABLE_MODE_PROMPT = """
ğŸš¨ í‘œ í˜•ì‹ ë‹µë³€ ëª¨ë“œ í™œì„±í™” - ì ˆëŒ€ ì¤€ìˆ˜ ğŸš¨

**ì‚¬ìš©ìê°€ í‘œ ëª¨ë“œë¥¼ í™œì„±í™”í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:**

1. ë‹µë³€ì˜ ì²« ì¤„ì€ ì œëª©ë§Œ ì‘ì„±

2. ì œëª© ë‹¤ìŒ ì¤„ë¶€í„° ì¦‰ì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ì‹œì‘

3. ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸(1., 2., 3.)ëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€

ã€í‘œ í¬ë§· ì˜ˆì‹œã€‘

| í•­ëª© | ì„¤ëª… |
|------|------|
| ì²« ë²ˆì§¸ | ë‚´ìš© |
| ë‘ ë²ˆì§¸ | ë‚´ìš© |

ã€URL í¬í•¨ã€‘

- ê° í–‰ì— ì°¸ê³  URLì´ ìˆìœ¼ë©´ ì¶”ê°€
- í‘œ ì•„ë˜ì— ì°¸ê³  ë¬¸ì„œ ì„¹ì…˜ ì¶”ê°€"""

# ê°œì„ ëœ USER_MESSAGE_TEMPLATE (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ê°•í™”, URL ë³´ì¡´ ê°•í™”)
USER_MESSAGE_TEMPLATE = """ã€ì´ì „ ëŒ€í™” ë§¥ë½ã€‘
{history}

ã€ê²€ìƒ‰ëœ ë¬¸ì„œã€‘
{context}

ã€ì‚¬ìš©ì ì§ˆë¬¸ã€‘
{query}

ã€âš ï¸ í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ - CRITICALã€‘

âœ… ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:

1. ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ìœ¼ë©´ "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ëª…ì‹œ
3. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
4. ë² ìŠ¬ë§í¬ ì§€ì› ì—¬ë¶€ëŠ” ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‹ ë¢°
5. URLì€ ë°˜ë“œì‹œ ì „ì²´ê²½ë¡œ í¬í•¨

âŒ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”:

- "ì•„ë§ˆë„ ~ì¼ ê²ƒì…ë‹ˆë‹¤"
- "ì¼ë°˜ì ìœ¼ë¡œ ~í•©ë‹ˆë‹¤"
- ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ ì¶”ê°€
- URL ì¤„ì„ë§ ì‚¬ìš© (https://... í˜•íƒœëŠ” ê¸ˆì§€)

ã€ë‹µë³€ í¬ë§· - í•„ìˆ˜ ì¤€ìˆ˜ã€‘

**ì œëª©** (í•œ ì¤„ - í•µì‹¬ì„ ëª…í™•íˆ)

1. ì²« ë²ˆì§¸ í¬ì¸íŠ¸ (ê°œí–‰ í›„ ìƒˆë¡œìš´ ì¤„ì—ì„œ ì‹œì‘)

2. ë‘ ë²ˆì§¸ í¬ì¸íŠ¸ (ê° í¬ì¸íŠ¸ ì‚¬ì´ì— ë¹ˆ ì¤„)

3. ì„¸ ë²ˆì§¸ í¬ì¸íŠ¸

(í•„ìš”ì— ë”°ë¼ 4, 5... ì¶”ê°€)

ã€URL ë° ì°¸ê³  ë¬¸ì„œ - í•„ìˆ˜ã€‘

ğŸ“š ì°¸ê³  ë¬¸ì„œ:

- ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ/ìœ ì§€]

- ë‹¤ë¥¸ ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ/ìœ ì§€]

(URLì´ ì—†ìœ¼ë©´ "ì¶œì²˜: [ë¬¸ì„œëª…]")

ã€ë§ˆì§€ë§‰ í™•ì¸ã€‘
í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"""

# ê°œì„ ëœ TABLE_USER_MESSAGE_TEMPLATE
TABLE_USER_MESSAGE_TEMPLATE = """ã€ê²€ìƒ‰ëœ ë¬¸ì„œã€‘
{context}

ã€ì‚¬ìš©ì ì§ˆë¬¸ã€‘
{query}

ã€â€¼ï¸ í‘œ í˜•ì‹ ë‹µë³€ í•„ìˆ˜ã€‘

ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ã€í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ã€‘

- ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì •ë³´ë§Œ ì‚¬ìš©
- ë¬¸ì„œì— ì—†ìœ¼ë©´ "í™•ì¸í•  ìˆ˜ ì—†ìŒ" í‘œê¸°
- URL ì „ì²´ê²½ë¡œ ìœ ì§€ (ì ˆëŒ€ ì¤„ì´ì§€ ë§ ê²ƒ)

ã€í‘œ í¬ë§· ì˜ˆì‹œã€‘

| í•­ëª© | ì„¤ëª… |
|------|------|
| ë‚´ìš©1 | ì„¤ëª…1 |
| ë‚´ìš©2 | ì„¤ëª…2 |

ã€ì°¸ê³  ë¬¸ì„œã€‘

- ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ]"""

# ë¹„êµ ëª¨ë“œ í”„ë¡¬í”„íŠ¸ - COMPARISON_CONTEXT_TEMPLATE
COMPARISON_CONTEXT_TEMPLATE = """ã€ì´ì „ ëŒ€í™” ë§¥ë½ã€‘
{history}

ã€ë¹„êµ ëŒ€ìƒã€‘
{topics}

ã€í˜„ì¬ ì§ˆë¬¸ã€‘
{query}

ã€ì§ˆë¬¸ ì˜ë„ã€‘
ì‚¬ìš©ìê°€ ì—¬ëŸ¬ í•­ëª©ì„ ë¹„êµí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œë§Œ ë¹„êµí•˜ì„¸ìš”."""

# ë¹„êµ ëª¨ë“œ í”„ë¡¬í”„íŠ¸ - COMPARISON_USER_TEMPLATE (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ê°•í™”)
COMPARISON_USER_TEMPLATE = """ã€ê²€ìƒ‰ëœ ë¬¸ì„œã€‘
{context}

ã€ë¹„êµ ë¶„ì„ ì§€ì¹¨ - í•„ìˆ˜ã€‘

âœ… ê° í•­ëª©ë³„ë¡œ:
1. ì •ì˜/ëª©ì  ëª…í™•íˆ êµ¬ë¶„
2. ë²”ìœ„/ì ìš© ëŒ€ìƒ ëª…ì‹œ
3. ë² ìŠ¬ë§í¬ ì§€ì› ì—¬ë¶€ (ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‹ ë¢°)
4. ê³µí†µì  ë° ì°¨ì´ì  ì •ë¦¬

âŒ í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€:
- ê° í•­ëª©ì€ ê²€ìƒ‰ëœ ë¬¸ì„œë§Œ ì‚¬ìš©
- ë¬¸ì„œì— ì—†ëŠ” ë¹„êµëŠ” ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€
- ë¶ˆëª…í™•í•˜ë©´ "ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŒ" í‘œê¸°

ã€í¬ë§·ã€‘

**í•­ëª©1 vs í•­ëª©2** (ë¹„êµ ì œëª©)

1. í•­ëª©1
   - ì •ì˜: [ê²€ìƒ‰ ê²°ê³¼]
   - ì§€ì›: [ê²€ìƒ‰ ê²°ê³¼]

2. í•­ëª©2
   - ì •ì˜: [ê²€ìƒ‰ ê²°ê³¼]
   - ì§€ì›: [ê²€ìƒ‰ ê²°ê³¼]

3. ë¹„êµ ìš”ì•½
   - ê³µí†µì : [ê²€ìƒ‰ ê²°ê³¼]
   - ì°¨ì´ì : [ê²€ìƒ‰ ê²°ê³¼]

ã€ì°¸ê³  ë¬¸ì„œã€‘

- ë¬¸ì„œëª… > ì„¹ì…˜ëª…
  URL: https://[ì „ì²´ê²½ë¡œ]

ì§ˆë¬¸: {query}"""

# ===== LangChain 1.0 RAG ì„œë¹„ìŠ¤ (ì™„ì „ ê°œì„ ) =====

class LangChainRAGService:
    """LangChain 1.0 ê¸°ë°˜ RAG ì„œë¹„ìŠ¤ (Phase 3-A ì™„ì „ ê°œì„ )"""

    def __init__(self):
        """Agent ì´ˆê¸°í™”"""
        logger.info("ğŸ”§ LangChain 1.0 RAG Service ì´ˆê¸°í™” ì¤‘...")
        logger.info(f"ğŸ“Š Config ì ìš©: ef_search={VECTOR_SEARCH_CONFIG['ef_search']}, threshold={VECTOR_SEARCH_CONFIG['similarity_threshold']}")

        # 1. ì„ë² ë”©
        self.embeddings = CustomEmbeddings()

        # 2. LLM
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            openai_api_key=OPENAI_API_KEY,
            streaming=True
        )

        # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°œì„ ë¨)
        self.base_prompt_template = ChatPromptTemplate.from_messages([
            ("system", VEDDY_SYSTEM_PROMPT),
            ("user", USER_MESSAGE_TEMPLATE)
        ])

        self.table_prompt_template = ChatPromptTemplate.from_messages([
            ("system", VEDDY_SYSTEM_PROMPT + TABLE_MODE_PROMPT),
            ("user", TABLE_USER_MESSAGE_TEMPLATE)
        ])

        # ë¹„êµ ëª¨ë“œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.comparison_prompt_template = ChatPromptTemplate.from_messages([
            ("system", VEDDY_SYSTEM_PROMPT),
            ("user", COMPARISON_CONTEXT_TEMPLATE + "\n\n" + COMPARISON_USER_TEMPLATE)
        ])

        # 4. Retriever ì‹±ê¸€í†¤
        self._retriever = None

        logger.info("âœ… LangChain 1.0 RAG Service ì´ˆê¸°í™” ì™„ë£Œ (í”„ë¡¬í”„íŠ¸ ì™„ì „ ê°œì„  + URL ìë™ ì¶”ê°€)")

    @property
    def retriever(self) -> SupabaseRetriever:
        """Retriever ì‹±ê¸€í†¤ (ë©”ëª¨ë¦¬ íš¨ìœ¨)"""
        if self._retriever is None:
            self._retriever = SupabaseRetriever(
                embeddings=self.embeddings,
                supabase_client=supabase_service,
                k=5
            )
        return self._retriever

    def _safe_format(self, template: ChatPromptTemplate, **kwargs) -> list:
        """ì•ˆì „í•œ format_messages (ì„ íƒì  íŒŒë¼ë¯¸í„° ì²˜ë¦¬)"""
        required_vars = template.input_variables
        safe_kwargs = {}

        for var in required_vars:
            if var in kwargs:
                safe_kwargs[var] = kwargs[var]
            else:
                safe_kwargs[var] = ""  # ê¸°ë³¸ê°’: ë¹ˆ ë¬¸ìì—´

        return template.format_messages(**safe_kwargs)

    def _normalize_response(self, response: str) -> str:
        """âœ… ì‘ë‹µ í…ìŠ¤íŠ¸ ì •ê·œí™” (ìëª¨ ë¶„ë¦¬ ë³µêµ¬)"""
        # 1. ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
        text = unicode_normalize('NFC', response)

        # 2. ì¤„ë°”ê¿ˆ í†µì¼
        text = text.replace('\r\n', '\n').replace('\r', '\n')

        # 3. 3ê°œ ì´ìƒ ì¤„ë°”ê¿ˆ â†’ 2ê°œ
        text = re.sub(r'\n{3,}', '\n\n', text)

        # 4. ê° ì¤„ ê³µë°± ì •ë¦¬
        lines = [re.sub(r' +', ' ', line.rstrip()) for line in text.split('\n')]

        # 5. ìµœì¢… ì •ë¦¬
        return '\n'.join(lines).strip()

    def process_query(
            self,
            user_id: str,
            query: str,
            table_mode: bool = False,
            supabase_client: Optional[SupabaseService] = None,
            history: str = None,
            comparison_info: dict = None
    ) -> Dict[str, Any]:
        """RAG ì¿¼ë¦¬ ì²˜ë¦¬ (history, comparison_info ì§€ì›)"""
        try:
            client = supabase_client if supabase_client else supabase_service

            if comparison_info is None:
                comparison_info = {"is_comparison": False, "topics": []}

            # í•­ìƒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            if comparison_info.get("is_comparison") and comparison_info.get("topics"):
                context_text, raw_chunks = self.retriever.search_multi_topic(
                    query,
                    comparison_info["topics"]
                )
                prompt_template = self.comparison_prompt_template
                topics_str = ", ".join(comparison_info["topics"])
                logger.info("ë¹„êµ ëª¨ë“œ ê²€ìƒ‰", extra={"topics": topics_str})
            else:
                context_text, raw_chunks = self.retriever.search_hybrid(query)
                prompt_template = self.table_prompt_template if table_mode else self.base_prompt_template
                topics_str = ""
                logger.info("ì¼ë°˜ ëª¨ë“œ ê²€ìƒ‰", extra={"table_mode": table_mode})

            # í¬ë§·
            messages = self._safe_format(
                prompt_template,
                context=context_text,
                query=query,
                history=history or "",
                topics=topics_str
            )

            response = self.llm.invoke(messages)
            ai_response = self._normalize_response(response.content)

            # ì†ŒìŠ¤ ID ì¶”ì¶œ
            source_chunk_ids = [chunk.get('id') for chunk in raw_chunks if chunk.get('id')]

            return {
                "user_query": query,
                "ai_response": ai_response,
                "source_chunks": raw_chunks,
                "source_chunk_ids": source_chunk_ids,
                "usage": {}
            }

        except Exception as e:
            logger.error(f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    def process_query_streaming(
            self,
            user_id: str,
            query: str,
            table_mode: bool = False,
            supabase_client: Optional[SupabaseService] = None,
            history: str = None,
            comparison_info: dict = None
    ) -> Generator[str, None, None]:
        """RAG ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì™„ì „ ê°œì„  - history, comparison_info ì§€ì›, í•­ìƒ í•˜ì´ë¸Œë¦¬ë“œ, URL ìë™ ì¶”ê°€)"""

        try:
            client = supabase_client if supabase_client else supabase_service

            if comparison_info is None:
                comparison_info = {"is_comparison": False, "topics": []}

            # ğŸ¯ í•­ìƒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            if comparison_info.get("is_comparison") and comparison_info.get("topics"):
                # ë¹„êµ ëª¨ë“œ: ë©€í‹° ì£¼ì œ ê²€ìƒ‰
                context_text, raw_chunks = self.retriever.search_multi_topic(
                    query,
                    comparison_info["topics"]
                )
                prompt_template = self.comparison_prompt_template
                topics_str = ", ".join(comparison_info["topics"])
                logger.info("ë¹„êµ ëª¨ë“œ ê²€ìƒ‰ ì‹œì‘", extra={"topics": topics_str})
            else:
                # ì¼ë°˜ ëª¨ë“œ: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í•­ìƒ!)
                context_text, raw_chunks = self.retriever.search_hybrid(query)
                prompt_template = self.table_prompt_template if table_mode else self.base_prompt_template
                topics_str = ""
                logger.info("ì¼ë°˜ ëª¨ë“œ ê²€ìƒ‰ ì‹œì‘", extra={"table_mode": table_mode})

            # í¬ë§· (history í¬í•¨)
            messages = self._safe_format(
                prompt_template,
                context=context_text,
                query=query,
                history=history or "",
                topics=topics_str
            )

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
            for chunk in self.llm.stream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    token = unicode_normalize('NFC', chunk.content)
                    yield token

            logger.info("ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            yield f"\n\n[ì˜¤ë¥˜ ë°œìƒ]\n{str(e)}"

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
langchain_rag_service = LangChainRAGService()
