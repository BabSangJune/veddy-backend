"""
ğŸ¯ í†µí•© ì±„íŒ… ì„œë¹„ìŠ¤ (Web + Teams ê³µìš©)

ì—­í• :
- History ë¡œë“œ
- ë¹„êµ ëª¨ë“œ ê°ì§€ (í–¥ìƒëœ ìë™ ê°ì§€)
- RAG ì²˜ë¦¬
- ë©”ì‹œì§€ ì €ì¥
- ì¡°ìœ¨ë§Œ ë‹´ë‹¹! (êµ¬ì²´ì  ë¡œì§ì€ ê° serviceì— ìœ„ì„)

ì±…ì„: ê° serviceë¥¼ ì¡°ìœ¨í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—­í• 
"""

from typing import AsyncGenerator, Dict, Optional, List
from services.langchain_rag_service import langchain_rag_service
from services.supabase_service import SupabaseService
from services.comparison_service import comparison_service
from services.history_service import history_service
from auth.user_service import user_service
from logging_config import get_logger
import asyncio
import json
import time

logger = get_logger(__name__)


class UnifiedChatService:
    """Web + Teams ê³µìš© ì±„íŒ… ì„œë¹„ìŠ¤ (í…Œì´ë¸” ëª¨ë“œ + ë¹„êµ ëª¨ë“œ ì¡°í•© ê°€ëŠ¥)"""

    async def process_chat(
            self,
            user_id: str,
            query: str,
            table_mode: bool = False,
            client_type: str = "web",  # "web" | "teams"
            supabase_client: Optional[SupabaseService] = None,
            email: Optional[str] = None,
            name: Optional[str] = None,
            conversation_context: Optional[List[Dict]] = None  # âœ… ì¶”ê°€
    ) -> AsyncGenerator[str, None]:
        """
        í†µí•© ì±„íŒ… ì²˜ë¦¬ (Web + Teams ëª¨ë‘ ì‚¬ìš©, í…Œì´ë¸” ëª¨ë“œ + ë¹„êµ ëª¨ë“œ ì¡°í•© ê°€ëŠ¥)

        íë¦„:
        1. ì‚¬ìš©ì ì •ë³´ í™•ì¸/ìƒì„±
        2. History ë¡œë“œ (DBì—ì„œ ìµœê·¼ ëŒ€í™”)
        3. ë¹„êµ ëª¨ë“œ ê°ì§€ (í–¥ìƒëœ ìë™ ê°ì§€)
        4. RAG ì²˜ë¦¬ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + LLM)
        5. ë©”ì‹œì§€ ì €ì¥ (DB)

        ì¸ì:
        - user_id: ì‚¬ìš©ì ID
        - query: ì‚¬ìš©ì ì§ˆë¬¸
        - table_mode: í‘œ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€ (ë‹¤ë¥¸ ëª¨ë“œì™€ ì¡°í•© ê°€ëŠ¥)
        - client_type: í´ë¼ì´ì–¸íŠ¸ íƒ€ì… ("web" | "teams")
        - supabase_client: Supabase í´ë¼ì´ì–¸íŠ¸
        - email: ì‚¬ìš©ì ì´ë©”ì¼ (ì„ íƒ)
        - name: ì‚¬ìš©ì ì´ë¦„ (ì„ íƒ)
        - conversation_context: êµ¬ì¡°í™”ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ (List[Dict])

        ìƒì„±(yield):
        ìŠ¤íŠ¸ë¦¬ë° í† í° (ê° ë¬¸ì)

        ì˜ˆì‹œ:
        async for token in unified_chat_service.process_chat(
        ...     "user123",
        ...     "IMO DCS vs EU MRV",
        ...     table_mode=True,
        ...     client_type="web"
        ... ):
        ...     print(token, end="", flush=True)
        """

        # ğŸ“‹ Step 1: ì‚¬ìš©ì ì •ë³´ í™•ì¸/ìƒì„±
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì í™•ì¸: {user_id}", extra={
            "client_type": client_type,
            "email": email
        })

        user_fk = await user_service.get_or_create_user(
            user_id=user_id,
            email=email,
            name=name,
            auth_type=client_type
        )

        # ğŸ“š Step 2: History ë¡œë“œ
        logger.info("ğŸ“¥ History ë¡œë“œ ì‹œì‘")

        history_text = await history_service.load_conversation_history(
            user_id=user_id,
            supabase_client=supabase_client
        )

        if history_text:
            logger.info(f"âœ… History ë¡œë“œ ì™„ë£Œ: {len(history_text)} ê¸€ì")
        else:
            logger.info("â„¹ï¸ History ì—†ìŒ (ì²« ëŒ€í™”)")

        # ğŸ” Step 3: ë¹„êµ ëª¨ë“œ ê°ì§€ (í–¥ìƒëœ ë²„ì „)
        logger.info("ğŸ” ë¹„êµ ëª¨ë“œ ê°ì§€ ì‹œì‘")

        comparison_info = comparison_service.detect_comparison_mode(
            query=query,
            history=history_text,
            conversation_context=conversation_context  # âœ… êµ¬ì¡°í™”ëœ history ì „ë‹¬
        )

        if comparison_info.get("is_comparison"):
            logger.info(f"âœ… ë¹„êµ ëª¨ë“œ ê°ì§€", extra={
                "topics": comparison_info.get("topics"),
                "confidence": comparison_info.get("confidence"),
                "method": comparison_info.get("detection_method")
            })
        else:
            logger.info("â„¹ï¸ ì¼ë°˜ ëª¨ë“œ")

        # ğŸ¯ Step 4: RAG ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)
        logger.info("ğŸ” RAG ì²˜ë¦¬ ì‹œì‘", extra={
            "table_mode": table_mode,
            "is_comparison": comparison_info.get("is_comparison"),
            "detection_method": comparison_info.get("detection_method")
        })

        full_response = ""
        source_chunk_ids = []

        try:
            start_time = time.time()

            logger.info("ğŸ” ê²€ìƒ‰ ì‹œì‘", extra={
                "search_mode": "comparison" if comparison_info.get("is_comparison") else "normal",
                "table_mode": table_mode
            })

            for token in langchain_rag_service.process_query_streaming(
                    user_id=user_id,
                    query=query,
                    table_mode=table_mode,  # âœ… ë…ë¦½ì ìœ¼ë¡œ ì „ë‹¬
                    supabase_client=supabase_client,
                    history=history_text,
                    comparison_info=comparison_info,
                    conversation_context=conversation_context  # âœ… ì¶”ê°€
            ):
                # â±ï¸ ìˆ˜ë™ íƒ€ì„ì•„ì›ƒ ì²´í¬ (120ì´ˆ)
                elapsed = time.time() - start_time
                if elapsed > 120.0:
                    logger.error(f"â±ï¸ RAG íƒ€ì„ì•„ì›ƒ ({elapsed:.1f}ì´ˆ ê²½ê³¼)")
                    error_msg = "ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                    yield f" {json.dumps({'type': 'error', 'error': error_msg}, ensure_ascii=False)}\n\n"
                    return

                # ğŸ”¥ í† í° ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë°
                if token:
                    full_response += token
                    yield token

                # ì´ë²¤íŠ¸ ë£¨í”„ì— ì–‘ë³´ (ì‘ë‹µì„± í–¥ìƒ)
                await asyncio.sleep(0)

            logger.info(f"âœ… RAG ì™„ë£Œ", extra={
                "length": len(full_response),
                "elapsed": f"{time.time() - start_time:.1f}ì´ˆ"
            })

        except asyncio.TimeoutError:
            logger.error("â±ï¸ RAG íƒ€ì„ì•„ì›ƒ (120ì´ˆ)")
            error_msg = "ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            yield f" {json.dumps({'type': 'error', 'error': error_msg}, ensure_ascii=False)}\n\n"
            return

        except Exception as e:
            logger.error(f"âŒ RAG ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            error_msg = f"ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}"
            yield f" {json.dumps({'type': 'error', 'error': error_msg}, ensure_ascii=False)}\n\n"
            return

        # ğŸ’¾ Step 5: ë©”ì‹œì§€ ì €ì¥
        logger.info("ğŸ’¾ ë©”ì‹œì§€ ì €ì¥", extra={
            "table_mode": table_mode,
            "is_comparison": comparison_info.get("is_comparison")
        })

        save_success = await history_service.save_message(
            user_id=user_id,
            user_fk=user_fk,
            query=query,
            response=full_response,
            table_mode=table_mode,
            comparison_mode=comparison_info.get("is_comparison"),
            source_chunk_ids=source_chunk_ids,
            supabase_client=supabase_client
        )

        if save_success:
            logger.info("âœ… ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì )")

        # âœ¨ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
        logger.info(f"âœ¨ ì±„íŒ… ì²˜ë¦¬ ì™„ë£Œ", extra={
            "client_type": client_type,
            "length": len(full_response),
            "table_mode": table_mode,
            "is_comparison": comparison_info.get("is_comparison")
        })
        yield f" {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"

    async def process_chat_non_streaming(
            self,
            user_id: str,
            query: str,
            table_mode: bool = False,
            client_type: str = "web",
            supabase_client: Optional[SupabaseService] = None,
            email: Optional[str] = None,
            name: Optional[str] = None,
            conversation_context: Optional[List[Dict]] = None  # âœ… ì¶”ê°€
    ) -> Dict[str, any]:
        """
        ë¹„ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì²˜ë¦¬ (Teams ë´‡ìš©, ì „ì²´ ì‘ë‹µì„ í•œ ë²ˆì— ë°˜í™˜)

        ì¥ì :
        - ì „ì²´ ì‘ë‹µ í•œ ë²ˆì— ìˆ˜ì‹ 
        - Teams ì ì‘í˜• ì¹´ë“œ ë“± êµ¬ì„±ëœ ì‘ë‹µì— ì í•©

        ë°˜í™˜:
        {
            "response": "ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸",
            "source_chunk_ids": ["chunk1", "chunk2"],
            "is_comparison": True/False,
            "topics": ["A", "B"],
            "table_mode": bool
        }
        """

        full_response = ""

        # ìŠ¤íŠ¸ë¦¬ë° í† í° ìˆ˜ì§‘
        async for token in self.process_chat(
                user_id=user_id,
                query=query,
                table_mode=table_mode,
                client_type=client_type,
                supabase_client=supabase_client,
                email=email,
                name=name,
                conversation_context=conversation_context  # âœ… ì „ë‹¬
        ):
            # ì—ëŸ¬ë‚˜ ì™„ë£Œ ë©”ì‹œì§€ëŠ” ì œì™¸
            if token.startswith(" "):
                try:
                    data = json.loads(token[1:].strip())
                    if data.get("type") == "done":
                        break
                except:
                    pass
            else:
                full_response += token

        # ë¹„êµ ëª¨ë“œ ì¬ê°ì§€ (ì´ë¯¸ ê°ì§€ë˜ì—ˆì§€ë§Œ ë°˜í™˜ìš©)
        comparison_info = comparison_service.detect_comparison_mode(query, "")

        return {
            "response": full_response,
            "is_comparison": comparison_info.get("is_comparison"),
            "topics": comparison_info.get("topics"),
            "user_id": user_id,
            "client_type": client_type,
            "table_mode": table_mode  # âœ… ì¶”ê°€
        }


# âœ… ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
unified_chat_service = UnifiedChatService()
