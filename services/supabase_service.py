# services/supabase_service.py (âœ¨ get_document_by_source_id ë©”ì„œë“œ ì¶”ê°€)

from supabase import create_client, Client
from typing import List, Dict, Any, Optional
from config import SUPABASE_URL, SUPABASE_KEY, SUPABASE_SERVICE_ROLE_KEY
from unicodedata import normalize as unicode_normalize
from config import VECTOR_SEARCH_CONFIG
from datetime import datetime
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class SupabaseService:
    # âœ… í´ë˜ìŠ¤ ë ˆë²¨ í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)
    _service_role_client: Optional[Client] = None

    def __init__(self, access_token: Optional[str] = None):
        """
        Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

        Args:
            access_token: ì‚¬ìš©ì JWT í† í° (Noneì´ë©´ Service Role ì‚¬ìš©)
        """
        if access_token:
            # ğŸ” ì‚¬ìš©ì í† í°ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (RLS ì ìš©ë¨)
            self.client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
            self.client.postgrest.auth(access_token)
            logger.info("âœ… Supabase ì‚¬ìš©ì í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (RLS í™œì„±í™”)")
        else:
            # ğŸ”‘ Service Role í´ë¼ì´ì–¸íŠ¸ (ê´€ë¦¬ììš©, RLS ìš°íšŒ)
            # âœ… í´ë˜ìŠ¤ ë ˆë²¨ ì‹±ê¸€í†¤ ì¬ì‚¬ìš©
            if SupabaseService._service_role_client is None:
                SupabaseService._service_role_client = create_client(
                    SUPABASE_URL,
                    SUPABASE_SERVICE_ROLE_KEY
                )
                logger.info("âœ… Supabase Service Role í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìµœì´ˆ)")
            else:
                logger.debug("â™»ï¸  ê¸°ì¡´ Service Role í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©")

            self.client = SupabaseService._service_role_client

    def test_connection(self) -> bool:
        """Supabase ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = self.client.table("documents").select("id").limit(1).execute()
            logger.info("âœ… Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    # ==================== documents ====================

    def get_document_by_source_id(self, source: str, source_id: str) -> Optional[Dict]:
        """
        âœ… Source IDë¡œ ê¸°ì¡´ ë¬¸ì„œ ì¡°íšŒ (ë³€ê²½ ê°ì§€ìš©)

        Args:
            source: ë¬¸ì„œ ì¶œì²˜ (ì˜ˆ: "confluence")
            source_id: ì¶œì²˜ ë‚´ ê³ ìœ  ID (ì˜ˆ: Confluence page_id)

        Returns:
            ê¸°ì¡´ ë¬¸ì„œ ì •ë³´ ë˜ëŠ” None
        """
        try:
            response = self.client.table("documents").select("*").eq(
                "source", source
            ).eq(
                "source_id", source_id
            ).limit(1).execute()

            if response.data:
                logger.debug(f"ğŸ“‹ ê¸°ì¡´ ë¬¸ì„œ ì¡°íšŒ ì„±ê³µ: {source}/{source_id}")
                return response.data[0]

            logger.debug(f"ğŸ“‹ ê¸°ì¡´ ë¬¸ì„œ ì—†ìŒ: {source}/{source_id}")
            return None

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨ ({source}/{source_id}): {e}")
            return None

    def add_document(
            self,
            source: str,
            source_id: str,
            title: str,
            content: str,
            metadata: Dict,
            created_at: Optional[datetime] = None,
            updated_at: Optional[datetime] = None
    ) -> Dict:
        """
        ë¬¸ì„œ ì €ì¥ ë˜ëŠ” ì—…ë°ì´íŠ¸ (Upsert)
        - created_at, updated_at: Confluenceì˜ ì‹¤ì œ ì‹œê°„ ì‚¬ìš©

        Args:
            source: ë¬¸ì„œ ì¶œì²˜
            source_id: ì¶œì²˜ ë‚´ ê³ ìœ  ID
            title: ë¬¸ì„œ ì œëª©
            content: ë¬¸ì„œ ë‚´ìš©
            metadata: ë©”íƒ€ë°ì´í„°
            created_at: ìƒì„± ì‹œê°„ (Confluenceì—ì„œ ë°›ì€ ê°’)
            updated_at: ìˆ˜ì • ì‹œê°„ (Confluenceì—ì„œ ë°›ì€ ê°’)

        Returns:
            ì €ì¥ëœ ë¬¸ì„œ ì •ë³´
        """
        try:
            normalized_title = unicode_normalize('NFC', title)
            normalized_content = unicode_normalize('NFC', content)

            doc_data = {
                "source": source,
                "source_id": source_id,
                "title": normalized_title,
                "content": normalized_content,
                "metadata": metadata,
                # âœ… Confluence ì‹œê°„ ì‚¬ìš© (ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„)
                "created_at": created_at.isoformat() if created_at else datetime.now().isoformat(),
                "updated_at": updated_at.isoformat() if updated_at else datetime.now().isoformat(),
            }

            try:
                response = self.client.table("documents").upsert(
                    doc_data,
                    ignore_duplicates=False
                ).execute()

                if response.data:
                    logger.info(f"âœ… ë¬¸ì„œ ì €ì¥/ì—…ë°ì´íŠ¸: {normalized_title} (ìˆ˜ì •: {updated_at})")
                    return response.data[0]

            except Exception as upsert_error:
                # UPDATE ì‹œë„
                logger.warning(f"âš ï¸ UPSERT ì‹¤íŒ¨, UPDATE ì‹œë„: {upsert_error}")

                try:
                    response = self.client.table("documents").update(doc_data).eq(
                        "source_id", source_id
                    ).execute()

                    if response.data:
                        logger.info(f"âœ… ë¬¸ì„œ ì—…ë°ì´íŠ¸: {normalized_title}")
                        return response.data[0]
                except:
                    # INSERT ì‹œë„
                    response = self.client.table("documents").insert(doc_data).execute()
                    if response.data:
                        logger.info(f"âœ… ë¬¸ì„œ ìƒˆë¡œ ì €ì¥: {normalized_title}")
                        return response.data[0]

            logger.error(f"âŒ ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨")
            return {}

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def list_documents(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ëª©ë¡"""
        try:
            response = self.client.table("documents").select("*").eq(
                "is_active", True
            ).limit(limit).execute()
            return response.data
        except Exception as e:
            logger.error(f"âŒ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    # ==================== chunks ====================

    def add_chunk(self, document_id: str, chunk_number: int, content: str, embedding: List[float]) -> Dict:
        """
        ë¬¸ì„œ ì²­í¬ ì €ì¥ (âœ… ì •ê·œí™” ì¶”ê°€)
        """
        try:
            # âœ… ì €ì¥ ì „ ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFC)
            normalized_content = unicode_normalize('NFC', content)

            chunk_data = {
                "document_id": document_id,
                "chunk_number": chunk_number,
                "content": normalized_content,
                "embedding": embedding
            }

            response = self.client.table("document_chunks").insert(chunk_data).execute()

            if response:
                return response.data[0]
            else:
                logger.error(f"âŒ ì²­í¬ ì €ì¥ ì‹¤íŒ¨")
                return {}

        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            raise


    # services/supabase_service.pyì˜ SupabaseService í´ë˜ìŠ¤ì— ì¶”ê°€

    def delete_chunks_by_document_id(self, document_id: str) -> int:
        """
        âœ… íŠ¹ì • ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬ ì‚­ì œ (ì—…ë°ì´íŠ¸ ì‹œ ì¤‘ë³µ ë°©ì§€)

        Args:
            document_id: ë¬¸ì„œ ID

        Returns:
            ì‚­ì œëœ ì²­í¬ ê°œìˆ˜
        """
        try:
            # ì‚­ì œ ì „ ê°œìˆ˜ í™•ì¸
            count_response = self.client.table("document_chunks").select(
                "id", count="exact"
            ).eq("document_id", document_id).execute()

            count = len(count_response.data) if count_response.data else 0

            if count == 0:
                logger.debug(f"ğŸ—‘ï¸  ì‚­ì œí•  ì²­í¬ ì—†ìŒ (document_id: {document_id})")
                return 0

            # ì²­í¬ ì‚­ì œ
            self.client.table("document_chunks").delete().eq(
                "document_id", document_id
            ).execute()

            logger.info(f"ğŸ—‘ï¸  ì²­í¬ ì‚­ì œ ì™„ë£Œ: {count}ê°œ (document_id: {document_id})")
            return count

        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ì‚­ì œ ì‹¤íŒ¨ (document_id: {document_id}): {e}")
            return 0


    def add_chunks_batch(self, chunks_data: List[Dict[str, Any]]) -> int:
        """
        âœ… ë‹¤ì¤‘ ì²­í¬ ë°°ì¹˜ ì €ì¥ (ì„±ëŠ¥ ìµœì í™”: N+1 ì¿¼ë¦¬ ì œê±°)

        14,000íšŒ ì¿¼ë¦¬ â†’ 1,400íšŒë¡œ 91% ê°ì†Œ!

        Args:
            chunks_data: ì €ì¥í•  ì²­í¬ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            [
                {"document_id": "...", "chunk_number": 1, "content": "...", "embedding": [...]},
                {"document_id": "...", "chunk_number": 2, "content": "...", "embedding": [...]},
                ...
            ]

        Returns:
            ì €ì¥ëœ ì²­í¬ ê°œìˆ˜
        """
        if not chunks_data:
            return 0

        import time

        batch_size = 10  # Supabase ê¶Œì¥: í•œ ë²ˆì— 10ê°œì”©
        total_saved = 0
        start_time = time.time()

        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²­í¬ ì €ì¥ ì‹œì‘: {len(chunks_data)}ê°œ ì²­í¬")

        try:
            # 10ê°œì”© ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥
            for i in range(0, len(chunks_data), batch_size):
                batch = chunks_data[i:i+batch_size]

                try:
                    response = self.client.table("document_chunks").insert(batch).execute()
                    saved_count = len(response.data) if response.data else 0
                    total_saved += saved_count

                    elapsed = time.time() - start_time
                    batch_num = (i // batch_size) + 1
                    print(f"  âœ… ë°°ì¹˜ {batch_num}: {saved_count}ê°œ ì €ì¥ ({elapsed:.2f}ì´ˆ)")

                except Exception as e:
                    logger.error(f"âŒ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}-{i+len(batch)}): {e}")
                    # ê³„ì† ì§„í–‰ (ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©)
                    continue

            elapsed = time.time() - start_time
            logger.info(f"âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {total_saved}ê°œ ì²­í¬ ì €ì¥ë¨ ({elapsed:.2f}ì´ˆ)")

            return total_saved

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return total_saved

    def search_chunks(self, embedding: List[float], limit: int = 5,
                      threshold: float = None, ef_search: int = None) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (config ê¸°ë°˜ + ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)
        """
        import time

        # âœ… configì—ì„œ ê¸°ë³¸ê°’ ìë™ ì ìš©
        config_threshold = VECTOR_SEARCH_CONFIG['similarity_threshold']
        config_ef_search = VECTOR_SEARCH_CONFIG['ef_search']

        threshold = threshold or config_threshold
        ef_search = ef_search or config_ef_search

        start_time = time.time()

        try:
            logger.info(f"ğŸ” ê²€ìƒ‰ ì‹œì‘ | ef={ef_search} | threshold={threshold} | limit={limit}")

            # RPC í˜¸ì¶œ
            response = self.client.rpc('match_documents', {
                'query_embedding': embedding,
                'match_count': limit,
                'match_threshold': threshold,
                'ef_search_value': ef_search
            }).execute()

            data = response.data if hasattr(response, 'data') else response

            if not data:
                elapsed = (time.time() - start_time) * 1000
                logger.warning(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ | ef={ef_search} | ì‹œê°„={elapsed:.2f}ms")
                return []

            logger.info(f"âœ… RPC ì‘ë‹µ: {len(data)}ê°œ")

            results = []
            similarities = []

            for i, item in enumerate(data, 1):
                chunk_id = item.get('id')
                doc_id = item.get('document_id')
                content = item.get('content', '')
                similarity = item.get('similarity', 0.0)
                title = item.get('title', 'ì œëª© ì—†ìŒ')
                source = item.get('source', 'confluence')
                metadata = item.get('metadata', {})

                similarities.append(similarity)

                chunk_data = {
                    'id': chunk_id,
                    'document_id': doc_id,
                    'content': content,
                    'similarity': similarity,
                    'title': title,
                    'source': source,
                    'url': metadata.get('url') or metadata.get('page_url', ''),
                    'metadata': metadata
                }

                results.append(chunk_data)

            elapsed = (time.time() - start_time) * 1000
            avg_similarity = sum(similarities) / len(similarities) if similarities else 0

            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ | ef_search={ef_search} | "
                        f"ì‹œê°„={elapsed:.2f}ms | ê²°ê³¼={len(results)}ê°œ | "
                        f"í‰ê· ìœ ì‚¬ë„={avg_similarity:.3f}")

            return results

        except Exception as e:
            elapsed = (time.time() - start_time) * 1000
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨ | ef={ef_search} | ì‹œê°„={elapsed:.2f}ms | ì˜¤ë¥˜={str(e)}")
            import traceback
            traceback.print_exc()
            return []

    # ==================== messages ====================

    def save_message(self, user_id: str, user_query: str, ai_response: str,
                     source_chunk_ids: Optional[List[str]] = None,
                     usage: Optional[Dict] = None) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì €ì¥"""
        data = {
            "user_id": user_id,
            "user_query": user_query,
            "ai_response": ai_response,
            "source_chunk_ids": source_chunk_ids or [],
            "usage": usage or {}
        }
        try:
            response = self.client.table("messages").insert(data).execute()
            return response.data[0] if response.data else {}
        except Exception as e:
            logger.error(f"âš ï¸ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {}

# âœ… ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ (Service Role - ê´€ë¦¬ìš©)
supabase_service = SupabaseService()
