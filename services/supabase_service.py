# services/supabase_service.py

from supabase import create_client, Client
from typing import List, Dict, Any, Optional
from config import SUPABASE_URL, SUPABASE_KEY, SUPABASE_SERVICE_ROLE_KEY
from unicodedata import normalize as unicode_normalize
import logging

logger = logging.getLogger(__name__)

class SupabaseService:
    # âœ… í´ë˜ìŠ¤ ë ˆë²¨ í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)
    _service_role_client: Optional[Client] = None

    def __init__(self, access_token: Optional[str] = None):
        """
        Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

        Args:
            access_token: ì‚¬ìš©ì JWT í† í° (Noneì´ë©´ Service Role ì‚¬ìš©)
        """
        if access_token:
            # ğŸ” ì‚¬ìš©ì í† í°ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (RLS ì ìš©ë¨)
            self.client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
            self.client.postgrest.auth(access_token)
            logger.info("âœ… Supabase ì‚¬ìš©ì í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (RLS í™œì„±í™”)")
        else:
            # ğŸ”‘ Service Role í´ë¼ì´ì–¸íŠ¸ (ê´€ë¦¬ììš©, RLS ìš°íšŒ)
            # âœ… í´ë˜ìŠ¤ ë ˆë²¨ ì‹±ê¸€í†¤ ì¬ì‚¬ìš©
            if SupabaseService._service_role_client is None:
                SupabaseService._service_role_client = create_client(
                    SUPABASE_URL,
                    SUPABASE_SERVICE_ROLE_KEY
                )
                logger.info("âœ… Supabase Service Role í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìµœì´ˆ)")
            else:
                logger.debug("â™»ï¸  ê¸°ì¡´ Service Role í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©")

            self.client = SupabaseService._service_role_client

    def test_connection(self) -> bool:
        """Supabase ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = self.client.table("documents").select("id").limit(1).execute()
            logger.info("âœ… Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    # ==================== documents ====================

    def add_document(self, source: str, source_id: str, title: str, content: str, metadata: Dict) -> Dict:
        """
        ë¬¸ì„œ ì €ì¥ (âœ… ì •ê·œí™” ì¶”ê°€)
        """
        try:
            # âœ… ì €ì¥ ì „ ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFC)
            normalized_title = unicode_normalize('NFC', title)
            normalized_content = unicode_normalize('NFC', content)

            doc_data = {
                "source": source,
                "source_id": source_id,
                "title": normalized_title,
                "content": normalized_content,
                "metadata": metadata
            }

            response = self.client.table("documents").insert(doc_data).execute()

            if response:
                logger.info(f"âœ… ë¬¸ì„œ ì €ì¥: {normalized_title}")
                return response.data[0]
            else:
                logger.error(f"âŒ ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨")
                return {}

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def list_documents(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ëª©ë¡"""
        try:
            response = self.client.table("documents").select("*").eq(
                "is_active", True
            ).limit(limit).execute()
            return response.data
        except Exception as e:
            logger.error(f"âŒ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    # ==================== chunks ====================

    def add_chunk(self, document_id: str, chunk_number: int, content: str, embedding: List[float]) -> Dict:
        """
        ë¬¸ì„œ ì²­í¬ ì €ì¥ (âœ… ì •ê·œí™” ì¶”ê°€)
        """
        try:
            # âœ… ì €ì¥ ì „ ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFC)
            normalized_content = unicode_normalize('NFC', content)

            chunk_data = {
                "document_id": document_id,
                "chunk_number": chunk_number,
                "content": normalized_content,
                "embedding": embedding
            }

            response = self.client.table("document_chunks").insert(chunk_data).execute()

            if response:
                return response.data[0]
            else:
                logger.error(f"âŒ ì²­í¬ ì €ì¥ ì‹¤íŒ¨")
                return {}

        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def search_chunks(self, embedding: List[float], limit: int = 5,
                      threshold: float = 0.2, ef_search: int = 50) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (HNSW ef_search ì§€ì›)

        Args:
            embedding: ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0~1)
            ef_search: HNSW ê²€ìƒ‰ í’ˆì§ˆ íŒŒë¼ë¯¸í„° (20~100)
                       20-30: ë¹ ë¥¸ ê²€ìƒ‰
                       50-60: ê· í˜• (ê¸°ë³¸ ì¶”ì²œ)
                       80-100: ì •í™•ë„ ìš°ì„ 

        Returns:
            ê²€ìƒ‰ëœ ì²­í¬ ëª©ë¡
        """
        try:
            logger.info(f"ğŸ” ê²€ìƒ‰ ì‹œì‘ (limit={limit}, threshold={threshold}, ef_search={ef_search})")

            # RPC í˜¸ì¶œ (ef_search íŒŒë¼ë¯¸í„° ì¶”ê°€)
            response = self.client.rpc('match_documents', {
                'query_embedding': embedding,
                'match_count': limit,
                'match_threshold': threshold,
                'ef_search_value': ef_search  # âœ… ì¶”ê°€
            }).execute()

            # response.data ì¶”ì¶œ
            data = response.data if hasattr(response, 'data') else response

            if not data:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return []

            logger.info(f"âœ… RPC ì‘ë‹µ: {len(data)}ê°œ")

            results = []
            for i, item in enumerate(data, 1):
                chunk_id = item.get('id')
                doc_id = item.get('document_id')
                content = item.get('content', '')
                similarity = item.get('similarity', 0.0)
                title = item.get('title', 'ì œëª© ì—†ìŒ')
                source = item.get('source', 'confluence')
                metadata = item.get('metadata', {})

                logger.debug(f" [{i}] chunk_id={chunk_id}, doc_id={doc_id}, sim={similarity:.3f}")

                # ì²­í¬ ë°ì´í„° êµ¬ì„±
                chunk_data = {
                    'id': chunk_id,
                    'document_id': doc_id,
                    'content': content,
                    'similarity': similarity,
                    'title': title,
                    'source': source,
                    'url': metadata.get('url') or metadata.get('page_url', ''),
                    'metadata': metadata
                }

                if chunk_data['url']:
                    logger.debug(f" ğŸ”— URL: {chunk_data['url']}")

                results.append(chunk_data)

            logger.info(f"âœ… ìµœì¢… ê²°ê³¼: {len(results)}ê°œ ë°˜í™˜")
            return results

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []


    # ==================== messages ====================

    def save_message(self, user_id: str, user_query: str, ai_response: str,
                     source_chunk_ids: Optional[List[str]] = None,
                     usage: Optional[Dict] = None) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì €ì¥"""
        data = {
            "user_id": user_id,
            "user_query": user_query,
            "ai_response": ai_response,
            "source_chunk_ids": source_chunk_ids or [],
            "usage": usage or {}
        }
        try:
            response = self.client.table("messages").insert(data).execute()
            return response.data[0] if response.data else {}
        except Exception as e:
            logger.error(f"âš ï¸ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {}

# âœ… ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ (Service Role - ê´€ë¦¬ìš©)
supabase_service = SupabaseService()
