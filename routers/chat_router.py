
from fastapi import APIRouter, Depends, Request
from fastapi.responses import StreamingResponse
from typing import AsyncGenerator, Optional, Dict, List
from model.schemas import ChatRequest
from services.langchain_rag_service import langchain_rag_service
from services.supabase_service import SupabaseService
from auth.auth_service import verify_supabase_token
from auth.user_service import user_service
import asyncio
import re
import json
from datetime import datetime
from logging_config import get_logger, generate_request_id
import logging

base_logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/chat", tags=["chat"])

def detect_comparison_mode(query: str, history: str = "") -> Dict:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë¹„êµ ê°ì§€
    "ë‘ê°œ ì°¨ì´ë¥¼ ë¹„êµí•´ì¤˜" â†’ historyì—ì„œ IMO DCS, EU MRV ìë™ ì¶”ì¶œ
    """

    # 1. ë¹„êµ í‚¤ì›Œë“œ í™•ì¸
    comparison_keywords = ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸ì ", "ê³µí†µì ", "vs", "VS"]
    is_comparison = any(kw in query for kw in comparison_keywords)

    if not is_comparison:
        return {"is_comparison": False, "topics": []}

    # 2. ëª…ì‹œì  í† í”½ ì¶”ì¶œ (A vs B, Aì™€ B ë“±)
    vsmatch = re.search(r'([^\s,]+?)\s*(?:vs|VS|ì™€|vs)\s*([^\s,]+)', query, re.IGNORECASE)
    if vsmatch:
        topic1, topic2 = vsmatch.groups()
        return {
            "is_comparison": True,
            "topics": [topic1.strip(), topic2.strip()]
        }

    # 3. "ë‘ê°œ", "ë‘˜" ë“± ëŒ€ëª…ì‚¬ â†’ Historyì—ì„œ ìµœê·¼ 2ê°œ í† í”½ ì¶”ì¶œ
    pronouns = ["ë‘ê°œ", "ë‘˜", "ì–‘ìª½", "ì´ ë‘", "ì € ë‘"]
    if any(p in query for p in pronouns) and history:
        topics = extract_topics_from_history(history)
        if len(topics) >= 2:
            return {
                "is_comparison": True,
                "topics": topics[:2]  # ìµœê·¼ 2ê°œë§Œ
            }

    # 4. ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ
    words = query.split()
    topics = [w for w in words
              if len(w) > 1 and w.isupper() and w not in [",", "ì™€", "ì˜", "ëŠ”"]]

    if len(topics) >= 2:
        return {
            "is_comparison": True,
            "topics": topics[:2]
        }

    return {"is_comparison": False, "topics": []}

def extract_topics_from_history(history: str) -> List[str]:
    """
    Historyì—ì„œ ì£¼ìš” í† í”½ ì¶”ì¶œ (IMO DCS, EU MRV ë“±)
    """
    # ëŒ€ë¬¸ì ì•½ì–´ íŒ¨í„´ (IMO DCS, EU MRV ë“±)
    acronym_pattern = r'\b[A-Z]{2,}(?:\s+[A-Z]{2,})?\b'
    matches = re.findall(acronym_pattern, history)

    # ì¤‘ë³µ ì œê±° & ìµœê·¼ ìˆœ
    seen = set()
    topics = []
    for match in reversed(matches):
        normalized = re.sub(r'[^\w\s]', '', match).strip()
        if normalized and normalized not in seen and len(topics) < 3:
            topics.append(match)
            seen.add(normalized)

    return list(reversed(topics))  # ì›ë˜ ìˆœì„œ ë³µì›



# ===== ë©”ì¸ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ =====

@router.post("/stream")
async def chat_stream(
        request_body: ChatRequest,
        request: Request,
        user: dict = Depends(verify_supabase_token)
):
    """
    âœ¨ VEDDY ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ (Phase 3-A Final)

    ğŸ“‹ ê¸°ëŠ¥:
    1. í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ (ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ë§Œ)
    2. ë‹µë³€ í¬ë§· ê°•ì œ (ë²ˆí˜¸ + ë“¤ì—¬ì“°ê¸° + URL)
    3. í‘œ ëª¨ë“œ (TABLE_MODE_PROMPT)
    4. ë¹„êµ ëª¨ë“œ (ìë™ ê°ì§€ ë˜ëŠ” ìˆ˜ë™)
    5. History ì§€ì› (ì´ì „ ëŒ€í™” ìë™ ë¡œë“œ)
    6. URL ìë™ ì¶”ì¶œ (documents metadata)

    ğŸ“Š íë¦„:
    History ì¡°íšŒ â†’ Comparison ê°ì§€ â†’ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ â†’ LLM â†’ í¬ë§·íŒ… â†’ DB ì €ì¥ â†’ ì „ì†¡
    """

    user_id = user["user_id"]
    email = user.get("email")
    name = user.get("name")
    access_token = user["access_token"]

    # âœ… ìš”ì²­ ì¶”ì  ID ìƒì„±
    request_id = generate_request_id()
    logger = get_logger(__name__, user_id=user_id, request_id=request_id, email=email)

    logger.info("ğŸ“¨ ì±„íŒ… ìš”ì²­ ìˆ˜ì‹ ", extra={
        "query": request_body.query[:50],
        "table_mode": request_body.table_mode,
        "has_history": bool(request_body.history),
        "has_comparison": bool(request_body.comparison_info)
    })

    # âœ… ì‚¬ìš©ì ì •ë³´ í™•ì¸/ìƒì„±
    user_fk = await user_service.get_or_create_user(
        user_id=user_id,
        email=email,
        name=name,
        auth_type="general"
    )

    user_supabase = SupabaseService(access_token=access_token)

    # ===== PHASE 1: History ì¡°íšŒ/ì „ë‹¬ =====

    history_text = request_body.history or ""
    if not history_text:
        try:
            # ìµœê·¼ 10ê°œì˜ ëŒ€í™” ì¡°íšŒ
            recent_messages = user_supabase.client.table("messages") \
                .select("user_query,ai_response") \
                .eq("user_id", user_id) \
                .order("created_at", desc=True) \
                .limit(10) \
                .execute()

            # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ì˜¤ë˜ëœ ê²ƒë¶€í„°)
            messages = list(reversed(recent_messages.data)) if recent_messages.data else []

            history_parts = []
            for msg in messages:
                q = msg.get('user_query', '')[:100]
                a = msg.get('ai_response', '')[:150]
                if q and a:
                    history_parts.append(f"Q: {q}")
                    history_parts.append(f"A: {a}...")

            history_text = "\n\n".join(history_parts)
            logger.info("âœ… History ë¡œë“œ ì™„ë£Œ", extra={
                "history_messages": len(messages),
                "history_length": len(history_text)
            })
        except Exception as e:
            logger.warning(f"âš ï¸ History ì¡°íšŒ ì‹¤íŒ¨: {e}")
            history_text = ""

    # ===== PHASE 2: Comparison ê°ì§€/ì„¤ì • =====

    comparison_info = request_body.comparison_info
    if comparison_info is None:
        # ìë™ ê°ì§€
        comparison_info = detect_comparison_mode(request_body.query)
        if comparison_info["is_comparison"]:
            logger.info("ğŸ” Comparison ìë™ ê°ì§€", extra={
                "topics": comparison_info["topics"]
            })
    else:
        logger.info("ğŸ“Š Comparison ìˆ˜ë™ ì„¤ì •", extra={
            "topics": comparison_info.get("topics", [])
        })

    # ===== PHASE 3: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± =====

    async def generate_stream() -> AsyncGenerator[str, None]:
        full_response = ""
        source_chunk_ids = []

        try:
            logger.info("â–¶ï¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")

            async def rag_with_timeout():
                nonlocal full_response, source_chunk_ids

                # ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + RAG ì²˜ë¦¬
                logger.info("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘", extra={
                    "search_mode": "comparison" if comparison_info["is_comparison"] else "normal"
                })

                for token in langchain_rag_service.process_query_streaming(
                        user_id=user_id,
                        query=request_body.query,
                        table_mode=request_body.table_mode,
                        supabase_client=user_supabase,
                        history=history_text,  # âœ… History ì „ë‹¬
                        comparison_info=comparison_info  # âœ… Comparison ì „ë‹¬
                ):
                    if token:
                        full_response += token

            # â±ï¸ íƒ€ì„ì•„ì›ƒ ì„¤ì • (120ì´ˆ)
            try:
                await asyncio.wait_for(rag_with_timeout(), timeout=120.0)
            except asyncio.TimeoutError:
                logger.error("â±ï¸ RAG ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (120ì´ˆ)")
                yield f" {json.dumps({'type': 'error', 'error': 'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
                return

            logger.info("âœ… LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ", extra={"length": len(full_response)})

            # ===== PHASE 4: ì‘ë‹µ í¬ë§·íŒ… =====

            # 1. ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ì •ê·œí™” (1. ë’¤ì— ë¹ˆ ì¤„ ì¶”ê°€)
            formatted = re.sub(r'(\d+\.)\s+', r'\1\n\n', full_response)

            # 2. ì œëª© ì •ê·œí™” (# ë’¤ì— ë¹ˆ ì¤„)
            formatted = re.sub(r'(#{1,3})\s+([^\n]+)', r'\1 \2\n\n', formatted)

            # 3. ë¦¬ìŠ¤íŠ¸ í•­ëª© ì •ê·œí™”
            formatted = re.sub(r'(-\s+[^\n]+)', r'\1\n', formatted)

            # 4. ì°¸ê³  ë¬¸ì„œ ì„¹ì…˜ í™•ì¸
            if 'ì°¸ê³  ë¬¸ì„œ' not in formatted and 'ğŸ“š' not in formatted:
                formatted += '\n\nğŸ“š ì°¸ê³  ë¬¸ì„œ:\n(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)'

            # 5. ê³¼ë‹¤í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
            formatted = re.sub(r'\n{4,}', '\n\n', formatted)

            logger.info("ğŸ“ ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ")

            # ===== PHASE 5: DBì— ë©”ì‹œì§€ ì €ì¥ =====

            try:
                user_supabase.client.table("messages").insert({
                    "user_id": user_id,
                    "user_fk": user_fk,
                    "user_query": request_body.query,
                    "ai_response": formatted,
                    "source_chunk_ids": source_chunk_ids if source_chunk_ids else None,
                    "table_mode": request_body.table_mode,
                    "comparison_mode": comparison_info["is_comparison"],
                    "comparison_topics": comparison_info.get("topics", []),
                    "has_history": bool(history_text),
                    "usage": {},
                    "created_at": datetime.utcnow().isoformat()
                }).execute()

                logger.info("ğŸ’¾ ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ", extra={
                    "chunks": len(source_chunk_ids),
                    "response_length": len(formatted)
                })
            except Exception as save_error:
                logger.error(f"âŒ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {save_error}")

            # ===== PHASE 6: í´ë¼ì´ì–¸íŠ¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ =====

            logger.info("ğŸ“¤ í´ë¼ì´ì–¸íŠ¸ ì „ì†¡ ì‹œì‘")

            for i, char in enumerate(formatted):
                # ì£¼ê¸°ì ìœ¼ë¡œ ì—°ê²° í™•ì¸
                if i % 100 == 0 and await request.is_disconnected():
                    logger.warning(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€ ({i}ê¸€ì ì „ì†¡ í›„)")
                    return

                data = json.dumps({"token": char, "type": "token"}, ensure_ascii=False)
                output = f" {data}\n\n"
                yield output
                await asyncio.sleep(0.001)  # ì•½ê°„ì˜ ì§€ì—°ìœ¼ë¡œ ë¶€í•˜ ë¶„ì‚°

            # âœ… ì™„ë£Œ ì‹ í˜¸
            yield f" {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
            logger.info("âœ¨ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ (ì„±ê³µ)", extra={"total_length": len(formatted)})

        except asyncio.CancelledError:
            logger.warning("ğŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì·¨ì†Œë¨ (í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€)")
            return

        except Exception as e:
            logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)

            # ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
            error_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            if "timeout" in str(e).lower():
                error_msg = "ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
            elif "connection" in str(e).lower():
                error_msg = "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            elif "embedding" in str(e).lower():
                error_msg = "ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            elif "hybrid" in str(e).lower():
                error_msg = "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

            error_msg += " ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

            try:
                yield f" {json.dumps({'type': 'error', 'error': error_msg}, ensure_ascii=False)}\n\n"
            except:
                logger.error("ì—ëŸ¬ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨")

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream; charset=utf-8",
            "X-Request-ID": request_id
        }
    )
